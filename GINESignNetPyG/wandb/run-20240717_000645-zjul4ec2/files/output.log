BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
BN? True
batchnorm BN
hidden 6
BN? True
> /lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/model_utils/pyg_gnn_wrapper.py(154)forward()
-> laplacian_batch = reconstruct_laplacian_from_flat(laplacian, num_nodes_per_graph)
/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/model.py:102: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3675.)
  rand_out = F.linear(x_r.T.reshape(N*M, -1), self.weight[:, -1:], self.bias) #N*MxF
149  	        num_nodes_per_graph = scatter_add(batch.new_ones(x.size(0)), batch, dim=0, dim_size=batch_size).tolist()
150  	        max_num_nodes = max(num_nodes_per_graph)
151  	
152  	        import pdb; pdb.set_trace()
153  	        # Reconstruct the Laplacian matrix from the flattened form
154  ->	        laplacian_batch = reconstruct_laplacian_from_flat(laplacian, num_nodes_per_graph)
155  	
156  	        # Reshape x to (batch_size, num_nodes, num_features)
157  	        x = x.view(batch_size, -1, x.size(1))
158  	
159  	        # Perform batch matrix multiplication for each graph
tensor([ 1.0000, -0.5774,  0.0000,  ..., -0.4082,  0.0000,  1.0000],
       device='cuda:0')
> /lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/model_utils/pyg_gnn_wrapper.py(157)forward()
-> x = x.view(batch_size, -1, x.size(1))
torch.Size([100, 35, 35])
152  	        import pdb; pdb.set_trace()
153  	        # Reconstruct the Laplacian matrix from the flattened form
154  	        laplacian_batch = reconstruct_laplacian_from_flat(laplacian, num_nodes_per_graph)
155  	
156  	        # Reshape x to (batch_size, num_nodes, num_features)
157  ->	        x = x.view(batch_size, -1, x.size(1))
158  	
159  	        # Perform batch matrix multiplication for each graph
160  	        LX = torch.bmm(laplacian_batch, x)
161  	        x = torch.matmul(L, x)
162  	
100
torch.Size([2335, 128, 100])
163  	        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)
164  	        out = torch.cat([x, out], dim=-2)
165  	        N, D, M = out.shape
166  	        out = self.post_nn(out.view(N*M, -1))
167  	        # return x + out
168  	        return out.view(N, -1, M)
169  	
170  	    def message(self, x_i, x_j, edge_attr):
171  	        if edge_attr is not None:
172  	            #problem before: x_i is 3d, x_j is 2d
173  	            h = torch.cat([x_i, x_j, edge_attr.unsqueeze(-1).expand(-1, -1, x_i.shape[-1])], dim=1)
> /lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/model_utils/pyg_gnn_wrapper.py(160)forward()
-> LX = torch.bmm(laplacian_batch, x)
*** RuntimeError: Expected size for first two dimensions of batch2 tensor to be: [100, 35] but got: [100, 2335].
torch.Size([100, 2335, 128])
*** RuntimeError: shape '[100, -1, 2335, 100]' is invalid for input of size 29888000
*** RuntimeError: shape '[100, -1, 128, 100]' is invalid for input of size 29888000
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/train/zinc.py", line 260, in <module>
    run(config_path, cfg, create_dataset, create_model, train, test)
  File "/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/train.py", line 47, in run
    train_loss = train(train_loader, model, optimizer, device=cfg.device, num_samples=cfg.train.num_samples)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/train/zinc.py", line 77, in train
    loss = (model(data, rand_x).squeeze() - y).abs().mean()
            ^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/sign_net.py", line 149, in forward
    return self.gnn(data, x_rand)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/model.py", line 182, in forward
    x = layer(x, data.edge_index, edge_attr, data.laplacian, data.batch)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/Random-SignNet/GINESignNetPyG/core/model_utils/pyg_gnn_wrapper.py", line 160, in forward
    offset = 0
         ^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/lfs/hyperturing1/0/echoi1/env/micromamba/envs/graphenv/lib/python3.11/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit